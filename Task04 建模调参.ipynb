{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "sns 相关设置\n",
    "@return:\n",
    "\"\"\"\n",
    "# 声明使用 Seaborn 样式\n",
    "sns.set()\n",
    "# 有五种seaborn的绘图风格，它们分别是：darkgrid, whitegrid, dark, white, ticks。默认的主题是darkgrid。\n",
    "sns.set_style(\"whitegrid\")\n",
    "# 有四个预置的环境，按大小从小到大排列分别为：paper, notebook, talk, poster。其中，notebook是默认的。\n",
    "sns.set_context('talk')\n",
    "# 中文字体设置-黑体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决保存图像是负号'-'显示为方块的问题\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 解决Seaborn中文显示问题并调整字体大小\n",
    "sns.set(font='SimHei')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成预处理好的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train =pd.read_csv('data/train.csv')\n",
    "data_test_a = pd.read_csv('data/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对象特征和数值特征\n",
    "numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea,list(data_train.columns)))\n",
    "label = 'isDefault'\n",
    "numerical_fea.remove(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "for data in [data_train, data_test_a]:\n",
    "    data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "    data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "    data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转化成时间格式\n",
    "for data in [data_train, data_test_a]:\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d')\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    #构造时间特征\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x-startdate).dt.days\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [data_train, data_test_a]:\n",
    "    data['earliesCreditLine'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [data_train, data_test_a]:\n",
    "    data['grade'] = data['grade'].map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'G':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['grade', 'subGrade']: \n",
    "    temp_dict = data_train.groupby([col])['isDefault'].agg(['mean']).reset_index().rename(columns={'mean': col + '_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col + '_target_mean'].to_dict()\n",
    "\n",
    "    data_train[col + '_target_mean'] = data_train[col].map(temp_dict)\n",
    "    data_test_a[col + '_target_mean'] = data_test_a[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其他衍生变量 mean 和 std\n",
    "for df in [data_train, data_test_a]:\n",
    "    for item in ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9','n10','n11','n12','n13','n14']:\n",
    "        df['grade_to_mean_' + item] = df['grade'] / df.groupby([item])['grade'].transform('mean')\n",
    "        df['grade_to_std_' + item] = df['grade'] / df.groupby([item])['grade'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode']\n",
    "data_train = pd.get_dummies(data_train, columns=columns, drop_first=True)\n",
    "data_test_a = pd.get_dummies(data_test_a, columns=columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding 完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(['employmentTitle', 'postCode', 'title']):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(data_train[col].astype(str).values) + list(data_test_a[col].astype(str).values))\n",
    "    data_train[col] = le.transform(list(data_train[col].astype(str).values))\n",
    "    data_test_a[col] = le.transform(list(data_test_a[col].astype(str).values))\n",
    "print('Label Encoding 完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['issueDate'],axis=1)\n",
    "data_test_a = data_test_a.drop(['issueDate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 556800128.00 MB\n",
      "Memory usage after optimization is: 332000128.00 MB\n",
      "Decreased by 40.4%\n",
      "Memory usage of dataframe is 137600128.00 MB\n",
      "Memory usage after optimization is: 76800128.00 MB\n",
      "Decreased by 44.2%\n"
     ]
    }
   ],
   "source": [
    "# data_train =pd.read_csv('data/train.csv')\n",
    "# data_test_a = pd.read_csv('data/testA.csv')\n",
    "data_train = reduce_mem_usage(data_train)\n",
    "data_test_a = reduce_mem_usage(data_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Columns: 178 entries, id to regionCode_50\n",
      "dtypes: float16(156), float32(2), float64(9), int16(3), int32(3), int8(5)\n",
      "memory usage: 316.6 MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train.drop(['id','isDefault'],axis=1)\n",
    "x_test = data_test_a.drop(['id'],axis=1)\n",
    "y_train = data_train['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "        \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "# 调objective\n",
    "def custom_asymmetric_objective(y_true, y_pred):\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual<0, -2*residual, -2*residual)\n",
    "    hess = np.where(residual<0, 2.0, 2.0)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def custom_normal_train(y_true, y_pred):\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual<0, -2*(residual)/(y_true+1), -10*2*(residual)/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    hess = np.where(residual<0, 2/(y_true+1), 10*2/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def loglikelihood(y_true, y_pred):\n",
    "#     labels = train_data.get_label()\n",
    "    y_pred = 1. / (1. + np.exp(-y_pred))\n",
    "    grad = y_pred - y_true\n",
    "    hess = y_pred * (1. - y_pred)\n",
    "    return grad, hess\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    beta = 2\n",
    "    p = 1. / (1 + np.exp(-y_pred))\n",
    "    grad = p * ((beta - 1) * y_true + 1) - beta * y_true\n",
    "    hess = ((beta - 1) * y_true + 1) * p * (1.0 - p)\n",
    " \n",
    "    return grad, hess\n",
    "\n",
    "def custom_loss(y_true,y_pred):\n",
    "    eps=1e-15\n",
    "    y_pred = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    grad = C_FN*(-1*y_true)/y_pred + C_TP*y_true/(1-y_pred) + C_FP*(1-y_true)/(1-y_pred) + C_TN*(y_true-1)/y_pred\n",
    "    hess = C_FN*y_true/y_pred**2 + C_TP*y_true/(1-y_pred)**2 + C_FP*(1-y_true)/(1-y_pred)**2 + C_TN*(1-y_true)/y_pred**2\n",
    "    return grad,hess\n",
    "\n",
    "def logistic_obj(y_true, y_pred):\n",
    "    y = y_true\n",
    "    p = 1. / (1. + np.exp(-y_pred)) # 用于避免hessian矩阵中很多0\n",
    "    grad = p - y\n",
    "    hess = p * (1. - p)\n",
    "    grad = 9 * p * y + p - 10 * y\n",
    "    hess = (9 * y + 1) * (p * (1.0 - p))\n",
    "    return grad, hess\n",
    "\n",
    "def my_objective(y_true, y_pred):\n",
    "    d = y_pred-y_true\n",
    "    x = (10.+np.square(d))\n",
    "    grad = -20*d/np.square(x)\n",
    "    hess = 80*np.square(d)*np.power(x,-3)-20*np.power(x,-2)\n",
    "    return -grad, -hess\n",
    "\n",
    "from scipy.misc import derivative\n",
    "\n",
    "def focal_loss_lgb(y_true, y_pred):\n",
    "    a,g = 0.25, 1.0\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    return grad, hess\n",
    "\n",
    "objective = [\n",
    "    'binary'\n",
    "]\n",
    "best_obj = dict()\n",
    "for obj in objective:\n",
    "    model = LGBMRegressor(objective=obj)\n",
    "    \"\"\"预测并计算roc的相关指标\"\"\"\n",
    "    score = cross_val_score(model, x_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    best_obj[obj] = score\n",
    "\n",
    "# num_leaves\n",
    "best_leaves = dict()\n",
    "for leaves in num_leaves:\n",
    "    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0], num_leaves=leaves)\n",
    "    \"\"\"预测并计算roc的相关指标\"\"\"\n",
    "    score = cross_val_score(model, x_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    best_leaves[leaves] = score\n",
    "    \n",
    "# max_depth\n",
    "best_depth = dict()\n",
    "for depth in max_depth:\n",
    "    model = LGBMRegressor(objective=min(best_obj.items(), key=lambda x:x[1])[0],\n",
    "                          num_leaves=min(best_leaves.items(), key=lambda x:x[1])[0],\n",
    "                          max_depth=depth)\n",
    "    \"\"\"预测并计算roc的相关指标\"\"\"\n",
    "    score = cross_val_score(model, x_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    best_depth[depth] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=['0_initial','1_turning_obj','2_turning_leaves','3_turning_depth'], y=[0.143 ,0.122, 0.111, 0.109])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
